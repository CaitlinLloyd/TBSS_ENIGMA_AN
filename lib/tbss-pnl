#!/usr/bin/env python

# ===============================================================================
# tbss (2019) pipeline is written by-
#
# TASHRIF BILLAH
# Brigham and Women's Hospital/Harvard Medical School
# tbillah@bwh.harvard.edu
#
# ===============================================================================
# See details at https://github.com/pnlbwh/tbss
# Submit issues at https://github.com/pnlbwh/tbss/issues
# View LICENSE at https://github.com/pnlbwh/tbss/blob/master/LICENSE
# ===============================================================================

import argparse
from tbssUtil import FILEDIR, isfile, isdir, pjoin, move, copytree, copyfile, listdir, makeDirectory, check_call, \
    dirname, abspath, chdir, getcwd
from conversion import loadExecutable, read_imgs_masks, read_imgs, read_cases
from conversion.antsUtil import antsReg
from orderCases import orderCases
from multiprocessing import Pool
from psutil import cpu_count
from glob import glob
from plumbum.cmd import antsApplyTransforms
from plumbum import FG
from skeletonize import skeletonize
from roi_analysis import roi_analysis

def main():
    '''
    PNL-TBSS
    Use dtifit to generate FA, MD, AD, and RD.
    Template can be three fold:
    1. -e: ENIGMA template
    2. -a: ANTs template created from provided FA images
    3. -t: Other user defined template

    Non-linear registration is computed among the FA images and the template.
    Transforms (warp and affine) obtained from the above registration, are applied to the
    modality image to bring them to template space. The modality can be one of
    FA, MD, AD, RD etc (default FA).
    [-m, --modality]

    The modality images can be further warped to a standard space (an FA image).
    [-s, --space]

    ROI based statistics is obtained using an atlas (default JHU-White-Matter atlas).
    [-a, --atlas]
    [-l, --lookUp]

    ENIGMA template is in MNI space, subsequent JHU atlas based analysis is done by default
    For other templates, have the user specify -a, -l, -s
    '''

    print('''# ===============================================================================
# tbss (2019) pipeline is written by-
# 
# TASHRIF BILLAH
# Brigham and Women's Hospital/Harvard Medical School
# tbillah@bwh.harvard.edu
# 
# ===============================================================================
# See details at https://github.com/pnlbwh/tbss
# Submit issues at https://github.com/pnlbwh/tbss/issues
# View LICENSE at https://github.com/pnlbwh/tbss/blob/master/LICENSE
# ===============================================================================''')

    parser = argparse.ArgumentParser(
        description='TBSS at PNL encapsulating different protocols i.e FSL, ENIGMA, ANTs template etc.')

    parser.add_argument('--modality', type= str, default= 'FA', help= 'Modality={FA,MD,AD,RD,...} of images to run TBSS on')

    parser.add_argument('-i', '--input', type=str, required=True,
                        help='a directory with one particular Modality={FA,MD,AD,RD,...} images, or '
                             'a txt/csv file with dwi1,mask1\\ndwi2,mask2\\n... ; TBSS will start by creating FA, MD, AD, and RD, or '
                             'a txt/csv file with ModImg1\\nModImg2\\n... ; '
                             'TBSS will be done for specified Modality')

    parser.add_argument('-c', '--caselist', type=str, required=True,
                        help='caselist.txt where each line is a subject ID')

    parser.add_argument('-o', '--outDir', type=str, required=True,
                        help='where all outputs are saved in an organized manner')

    parser.add_argument('--template', type=str,
                        help='an FA image template (i.e ENIGMA, IIT), '
                             'if not specified, ANTs template will be created from provided images, '
                             'for ANTs template creation, you should provided FA images, '
                             'once ANTs template is created, you can run TBSS on non FA images using that template')

    parser.add_argument('--templateMask', type=str,
                        help='mask of the FA template, if not provided, one will be created')

    parser.add_argument('--skeleton', type=str,
                        help='skeleton of the FA template, if not provided, one will be created,'
                             'either provide all three of --skeleton, --skeletonMask, and --dist, or none of them')

    parser.add_argument('--skeletonMask', type=str,
                        help='mask of the provided skeleton')

    parser.add_argument('--skeletonMaskDst', type=str,
                        help='skeleton mask distance map')

    parser.add_argument('-s', '--space', type=str,
                        help='you may register your template (including ANTs) to another standard space i.e MNI, '
                             'not recommended for a template that is already in MNI space (i.e ENIGMA, IIT)')

    parser.add_argument('-l', '--labelMap', type=str,
                        help='labelMap (atlas) in standard space (i.e any WhiteMatter atlas from '
                             '~/fsl/data/atlas/, the atlas is used for ROI wise TBSS, '
                             'default= ~/fsl/data/atlases/JHU/JHU-ICBM-labels-1mm.nii.gz')

    parser.add_argument('--lut', type= str,
                         help='look up table for specified labelMap (atlas), default: FreeSurferColorLUT.txt')

    parser.add_argument('--qc', action='store_true', help= 'halt TBSS pipeline to let the user observe quality of registration')
    parser.add_argument('--avg', action='store_true', help= 'average Left/Right components of tracts in the atlas')
    parser.add_argument('--force', action='store_true', help='overwrite existing directory/file')


    parser.add_argument('-n','--ncpu', type= int,
                        help= 'number of processes/threads to use (-1 for all available, may slow down your system)', default= 4)

    diffusionMeasures = ['FA', 'MD', 'AD', 'RD']

    args = parser.parse_args()


    # write config file ====================================================================================
    if args.ncpu==-1:
        N_CPU= cpu_count()
    else:
        N_CPU= int(args.ncpu)


    with open(pjoin(FILEDIR, 'config.ini'), 'w') as f:
        f.write('[DEFAULT]\n')
        f.write(f'N_CPU = {args.ncpu}\n')
        f.write('diffusionMeasures = {}\n'.format((',').join(diffusionMeasures)))


    # check executables ====================================================================================
    apps = ['antsApplyTransforms',
            'antsRegistrationSyNQuick.sh',
            'antsMultivariateTemplateConstruction2.sh',
            'antsRegistration',
            'dtifit',
            'tbss_1_preproc',
            'tbss_skeleton',
            'distancemap']

    for exe in apps:
        loadExecutable(exe)
    print('All executables are found, program will begin now ...')

    args.modality= args.modality.upper()
    args.input= abspath(args.input)
    args.outDir= abspath(args.outDir)

    # organize images into different directories ===========================================================

    # outDir
    #    |
    # -----------------------------------------------------------------------------
    #    |           |             |                |        |       |
    #    |           |             |                |        |       |
    # transform   template        FA                MD       AD      RD
    #                              |       (same inner file structure as that of FA)
    #                              |
    #                 ----------------------------------------
    #                  |         |         |       |        |
    #                 preproc  origdata  warped  skeleton  roi
    #
    # copy all FA into FA directory
    # put all preprocessed data into preproc directory
    # keep all warp/affine in transform directory
    # output all warped images in warped directory
    # output all skeletons in skel directory
    # output ROI based analysis files in roi directory

    # define directories
    makeDirectory(args.outDir)
    modDir = pjoin(args.outDir, f'{args.modality}')
    makeDirectory(modDir, True)
    xfrmDir = pjoin(args.outDir, 'transform')
    preprocDir= pjoin(modDir, 'preproc')
    warpDir= pjoin(modDir, 'warped')
    skelDir= pjoin(modDir, 'skeleton')
    roiDir= pjoin(modDir, 'roi')

    # force creation of inner directories
    # makeDirectory(tempModDir, True)
    makeDirectory(warpDir, True)
    makeDirectory(skelDir, True)
    makeDirectory(roiDir, True)


    # if modality is not FA, check if 'transform' directory exists
    # warp and affine will be used from this directory to study non FA images
    if args.modality!='FA' and not isdir(xfrmDir):
        raise FileNotFoundError(f'{xfrmDir}/ containing Warp and affine from FA registration does not exist')

    cases= read_cases(args.caselist)

    ORGANIZE= True
    # calculate diffusion measures =========================================================================
    if isfile(args.input):
        # when input is a dwi/mask list
        try:
            from generate_diffusion_measures import generate_diffusion_measures
            from antsTemplate import antsMult

            for modality in diffusionMeasures:
                measureDir = pjoin(args.outDir, f'{modality}')
                makeDirectory(measureDir, args.force)

            dwImgs, masks= read_imgs_masks(args.input)

            dwImgs, masks= orderCases(dwImgs, cases, masks)

            pool= Pool(N_CPU)
            # need to generate diffusion measures first
            for dwImgPath, maskPath, caseId in zip(dwImgs, masks, cases):
                pool.apply_async(func= generate_diffusion_measures,
                                 args= (dwImgPath, maskPath, caseId, args.outDir))


            pool.close()
            pool.join()


            ORGANIZE = False


        # when input is a modality list
        except:
            modImgs= read_imgs(args.input)
            # check if input directory is modDir, if not copy
            for imgPath in modImgs:
                if dirname(imgPath) is not modDir:
                    check_call(f'cp {imgPath} {modDir}/', shell= True)


    # when input is a directory
    elif isdir(args.input):
        # check if input directory is modDir, if not copy
        if args.input is not modDir:
            check_call(f'cp -a {args.input}/*.nii.gz {modDir}/', shell= True)


    else:
        raise AttributeError(f'Invalid --input: {args.input}')


    # modality can be one of the diffusionMeasures= ['FA','MD','AD','RD']
    # we could use just listdir(), but the following would be more strict and safe
    modImgs = glob(pjoin(modDir, '*.nii.gz'))
    modImgs = orderCases(modImgs, cases)

    if ORGANIZE:
        for c, imgPath in zip(cases, modImgs):
            if imgPath is not f'{c}.nii.gz':
                # move(imgPath, pjoin(tempModDir, f'{c}_FA.nii.gz'))
                move(imgPath, pjoin(modDir, f'{c}.nii.gz'))


    # preprocessing ========================================================================================
    print('Preprocessing FA images: eroding them and zeroing the end slices ...')
    modDir= pjoin(args.outDir, args.modality)
    CURRDIR= getcwd()
    chdir(modDir)
    check_call('tbss_1_preproc *.nii.gz', shell= True) # creates 'FA' and 'origdata' folders
    chdir(CURRDIR)
    print('Index file location has changed, see ', pjoin(preprocDir, 'slicesdir', 'index.html'))

    # TODO
    # how should we handle masking of other diffusion measures by the FA_mask?

    # rename args.modality/FA to args.modality/preproc
    move(pjoin(modDir, 'FA'), preprocDir)

    # rename args.modality/args.modality/*.nii.gz to have proper modality keyword
    for path in glob(pjoin(preprocDir, '*.nii.gz')):
        move(path, path.replace('FA', args.modality))

    modImgs = glob(pjoin(preprocDir, f'*{args.modality}.nii.gz'))

    ANTS= False
    # create template ======================================================================================
    if not args.template and args.modality=='FA':
        ANTS= True
        print('Creating study specific template ...')
        # we could pass modImgs directly to antsMult(), instead saving them to a .txt file for logging
        # modImgs = glob(pjoin(args.outDir, f'{args.modality}', f'*{args.modality}*.nii.gz'))

        templatePath= pjoin(args.outDir, 'template/')
        makeDirectory(templatePath, args.force)

        antsMultCaselist = pjoin(args.outDir, 'antsMultCaselist.txt')
        check_call((' ').join(['ls', pjoin(preprocDir, f'*{args.modality}.nii.gz'), '>', antsMultCaselist]),
                   shell= True)

        # ATTN: antsMultivariateTemplateConstruction2.sh requires '/' at the end of templatePath
        # antsMult(antsMultCaselist, templatePath)
        # TODO: rename the template
        args.template= pjoin(templatePath, 'template0.nii.gz')

        # warp and affine to template0.nii.gz have been created for each case during template construction
        # so template directory should be the transform directory
        xfrmDir= templatePath

    # register each image to the template ==================================================================
    elif args.template:
        # find warp and affine of FA image to args.template for each case
        if args.modality=='FA':
            pool= Pool(N_CPU)
            for c, imgPath in zip(cases, modImgs):
                pool.apply_async(antsReg, (args.template, None, imgPath, pjoin(xfrmDir, f'{c}_FA')))

            pool.close()
            pool.join()

    # register template to a standard space ================================================================
    # useful when you would like to do ROI based analysis using an atlas
    # project the created/specified template to the space of atlas
    if args.space:
        outPrefix = pjoin(args.outDir, 'tmp2space')
        warp2space = outPrefix + '1Warp.nii.gz'
        trans2space = outPrefix + '0GenericAffine.mat'
        if not warp2space:
            antsReg(args.space, None, args.template, outPrefix)

        # TODO: rename the template
        args.template = outPrefix + 'Warped.nii.gz'


    for c, imgPath in zip(cases, modImgs):
        # generalize warp and affine
        warp2tmp= glob(pjoin(xfrmDir, f'{c}_FA*Warp.nii.gz'))[0]
        trans2tmp= glob(pjoin(xfrmDir, f'{c}_FA*GenericAffine.mat'))[0]
        output= pjoin(warpDir, f'{c}_{args.modality}_to_target.nii.gz')

        if not args.space:
            antsApplyTransforms[
                '-d', '3',
                '-i', imgPath,
                '-o', output,
                '-r', args.template,
                '-t', warp2tmp, trans2tmp,
            ] & FG

        else:
            antsApplyTransforms[
                '-d', '3',
                '-i', imgPath,
                '-o', output,
                '-r', args.space,
                '-t', warp2space, trans2space, warp2tmp, trans2tmp
            ] & FG



    if args.qc:
        # halt processing, pull up registered images for review
        pass


    # create skeleton for each subject
    modImgsInTarget= glob(pjoin(warpDir, f'*_{args.modality}_to_target.nii.gz'))
    modImgsInTarget= orderCases(modImgsInTarget, cases)

    skeletonize(modImgsInTarget, cases, args.modality, args.template, args.templateMask,
                args.skeleton, args.skeletonMask, args.skeletonMaskDst, args.outDir, skelDir, ANTS)


    skelImgsInSub= glob(pjoin(skelDir, f'*_{args.modality}_to_target_skel.nii.gz'))
    skelImgsInSub= orderCases(skelImgsInSub, cases)

    # roi based analysis
    if args.labelMap:
        roi_analysis(skelImgsInSub, cases, args.modality, args.labelMap, args.lut, modDir, roiDir, args.avg)

if __name__=='__main__':
    main()
